{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [],
   "source": [
    "#importing libraries\n",
    "import torch\n",
    "import torchvision\n",
    "import torchvision.transforms as transforms\n",
    "import torchvision.datasets as datasets\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import numpy as np\n",
    "import torch.nn.functional as F\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cuda:0\n"
     ]
    }
   ],
   "source": [
    "device = torch.device('cuda:0' if torch.cuda.is_available() else 'cpu')\n",
    "print(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [],
   "source": [
    "#parameters\n",
    "learning_rate = 0.001\n",
    "batch_size = 16"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Applying Transformations\n",
    "train_transformations = transforms.Compose([\n",
    "    transforms.Resize(128),\n",
    "    transforms.ColorJitter(brightness=0.5, contrast=0.5, saturation=0.5, hue=0.2),\n",
    "    transforms.RandomVerticalFlip(p=0.5),\n",
    "    transforms.RandomHorizontalFlip(p=0.5),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize(mean=[0.5, 0.5, 0.5], std=[0.5, 0.5, 0.5])\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_transformations = transforms.Compose([\n",
    "    transforms.Resize(128),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize(mean=[0.5, 0.5, 0.5], std=[0.5, 0.5, 0.5])\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [],
   "source": [
    "#loading and labelling training set\n",
    "train_set1 = datasets.ImageFolder(\"C://Users/Atharva/Dataset/train\", transform = train_transformations)\n",
    "#train_set2 = datasets.ImageFolder(\"C://Users/Atharva/Dataset/train\", transform = train_transformations2)\n",
    "#train_set = torch.utils.data.ConcatDataset([train_set1])\n",
    "train_dataloader = torch.utils.data.DataLoader(train_set1, batch_size=batch_size, shuffle=True, num_workers=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [],
   "source": [
    "classes = ['basketball_court', 'beach', 'forest', 'others', 'railway', 'swimming_pool', 'tennis_court']\n",
    "\n",
    "#used for rearranging predictions as the classes is sorted in alphabetical order and we need according to the classes mentioned in the competition\n",
    "req_classes = [1,2,3,7,4,6,5]\n",
    "\n",
    "test_set = datasets.ImageFolder(\"C://Users/Atharva/Dataset/test_set\", transform = test_transformations)\n",
    "\n",
    "test_dataloader = torch.utils.data.DataLoader(test_set, batch_size=batch_size, shuffle=True, num_workers=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [],
   "source": [
    "#testing the code\n",
    "images, labels = next(iter(train_dataloader))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [],
   "source": [
    "#for i in range(batch_size):\n",
    "#    test_image = (images[i]*0.5 + 0.5).permute(1, 2, 0)\n",
    "#    plt.imshow(test_image.numpy())\n",
    "#    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Network(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.conv1 = nn.Conv2d(in_channels=3, out_channels=64, kernel_size=5)\n",
    "        self.batchnorm1 = nn.BatchNorm2d(64)\n",
    "        self.droput_cnn = nn.Dropout(p=0.25)\n",
    "        self.conv2 = nn.Conv2d(in_channels=64, out_channels=64, kernel_size=3)\n",
    "        self.batchnorm2 = nn.BatchNorm2d(64)\n",
    "        self.conv3 = nn.Conv2d(in_channels=64, out_channels=128, kernel_size=3)\n",
    "        self.batchnorm3 = nn.BatchNorm2d(128)\n",
    "        self.conv4 = nn.Conv2d(in_channels=128, out_channels=128, kernel_size=3)\n",
    "        self.batchnorm4 = nn.BatchNorm2d(128)\n",
    "        self.conv5 = nn.Conv2d(in_channels=128, out_channels=256, kernel_size=3)\n",
    "        self.batchnorm5 = nn.BatchNorm2d(256)\n",
    "\n",
    "        self.fc1 = nn.Linear(in_features=256 * 2 * 2, out_features=1536)\n",
    "        self.droput_fcc = nn.Dropout(p=0.5)\n",
    "        self.fc2 = nn.Linear(in_features=1536, out_features=256)\n",
    "        self.out = nn.Linear(in_features=256, out_features=7)\n",
    "\n",
    "    def forward(self, t):\n",
    "        # Input Layer\n",
    "        x = t\n",
    "        \n",
    "        # 1st Hidden Layer\n",
    "        x = self.conv1(x)\n",
    "        x = self.batchnorm1(x)\n",
    "        x = F.relu(x)\n",
    "        x = F.max_pool2d(x, kernel_size=2, stride=2)\n",
    "        \n",
    "        # 2nd Hidden Layer\n",
    "        x = self.conv2(x)\n",
    "        x = self.batchnorm2(x)\n",
    "        x = F.relu(x)\n",
    "        x = F.max_pool2d(x, kernel_size=2, stride=2)\n",
    "        x = self.droput_cnn(x)\n",
    "        \n",
    "        # 3rd Hidden layer\n",
    "        x = self.conv3(x)\n",
    "        x = self.batchnorm3(x)\n",
    "        x = F.relu(x)\n",
    "        x = F.max_pool2d(x, kernel_size=2, stride=2)\n",
    "        \n",
    "        # 4th Hidden layer\n",
    "        x = self.conv4(x)\n",
    "        x = self.batchnorm4(x)\n",
    "        x = F.relu(x)\n",
    "        x = F.max_pool2d(x, kernel_size=2, stride=2)\n",
    "        x = self.droput_cnn(x)\n",
    "        \n",
    "        # 5th Hidden layer\n",
    "        x = self.conv5(x)\n",
    "        x = self.batchnorm5(x)\n",
    "        x = F.relu(x)\n",
    "        x = F.max_pool2d(x, kernel_size=2, stride=2)\n",
    "        \n",
    "        # 1st FCl\n",
    "        x = x.reshape(-1, 256 * 2 * 2)\n",
    "        x = self.fc1(x)\n",
    "        x = F.relu(x)\n",
    "        x = self.droput_fcc(x)\n",
    "        \n",
    "        # 2nd FCL\n",
    "        x = self.fc2(x)\n",
    "        x = F.relu(x)\n",
    "        x = self.droput_fcc(x)\n",
    "\n",
    "        output = F.log_softmax(self.out(x),dim = 1)\n",
    "        \n",
    "        return output\n",
    "\n",
    "network = Network().to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [],
   "source": [
    "#mention the loss function\n",
    "lambd = 1e-5\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = optim.Adam(network.parameters(),lr = learning_rate, weight_decay = lambd) # Calculate Loss\n",
    "#optimizer = optim.SGD(network.parameters(), lr= learning_rate, momentum=0.9, weight_decay = lambd)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train():\n",
    "    correct = 0\n",
    "    total = 0\n",
    "    running_loss = 0.0\n",
    "    \n",
    "    network.train()\n",
    "    for data in train_dataloader:\n",
    "        # get the inputs; data is a list of [inputs, labels]\n",
    "        images, labels = data\n",
    "        \n",
    "        images = images.to(device)\n",
    "        labels = labels.to(device)\n",
    "        # zero the parameter gradients\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        # forward + backward + optimize\n",
    "        outputs = network(images)\n",
    "        \n",
    "        loss = criterion(outputs, labels)\n",
    "        \n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        \n",
    "        # print statistics\n",
    "        running_loss += loss.item()\n",
    "        \n",
    "    network.eval()\n",
    "    with torch.no_grad():\n",
    "        for data in train_dataloader:\n",
    "            images, labels = data\n",
    "            images = images.to(device)\n",
    "            labels = labels.to(device)\n",
    "            \n",
    "            outputs = network(images)\n",
    "            \n",
    "            _, predicted = torch.max(outputs.data, 1)\n",
    "            total += labels.size(0)\n",
    "            correct += (predicted == labels).sum().item()\n",
    "    \n",
    "    return running_loss/len(train_dataloader.sampler), correct*100/total\n",
    "\n",
    "def test():\n",
    "    correct = 0\n",
    "    total = 0\n",
    "    running_loss = 0\n",
    "    network.eval()# it-disables-dropout\n",
    "    with torch.no_grad():\n",
    "        for data in test_dataloader:\n",
    "            \n",
    "            images, labels = data\n",
    "            images = images.to(device)\n",
    "            labels = labels.to(device)\n",
    "            \n",
    "            outputs = network(images)\n",
    "            \n",
    "            loss = criterion(outputs, labels)\n",
    "            \n",
    "            running_loss += loss.item()\n",
    "            \n",
    "            _, predicted = torch.max(outputs.data, 1)\n",
    "            total += labels.size(0)\n",
    "            correct += (predicted == labels).sum().item()\n",
    "            \n",
    "    return running_loss/len(test_dataloader.sampler), correct*100/total"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Updating Model:  18.94736842105263\n",
      "Epoch: 1    Train_loss.: 0.1128   Train_acc: 20.18   Test_loss.: 0.1292   Test_acc: 18.95\n",
      "Updating Model:  24.210526315789473\n",
      "Epoch: 2    Train_loss.: 0.1087   Train_acc: 38.93   Test_loss.: 0.1019   Test_acc: 24.21\n",
      "Updating Model:  33.68421052631579\n",
      "Epoch: 3    Train_loss.: 0.1000   Train_acc: 39.64   Test_loss.: 0.0902   Test_acc: 33.68\n",
      "Not changed:  33.68421052631579\n",
      "Epoch: 4    Train_loss.: 0.0932   Train_acc: 50.54   Test_loss.: 0.0875   Test_acc: 32.63\n",
      "Updating Model:  35.78947368421053\n",
      "Epoch: 5    Train_loss.: 0.0894   Train_acc: 35.18   Test_loss.: 0.0919   Test_acc: 35.79\n",
      "Updating Model:  38.94736842105263\n",
      "Epoch: 6    Train_loss.: 0.0897   Train_acc: 50.36   Test_loss.: 0.0858   Test_acc: 38.95\n",
      "Not changed:  38.94736842105263\n",
      "Epoch: 7    Train_loss.: 0.0826   Train_acc: 48.57   Test_loss.: 0.0994   Test_acc: 26.32\n",
      "Not changed:  38.94736842105263\n",
      "Epoch: 8    Train_loss.: 0.0805   Train_acc: 49.11   Test_loss.: 0.0842   Test_acc: 34.74\n",
      "Not changed:  38.94736842105263\n",
      "Epoch: 9    Train_loss.: 0.0814   Train_acc: 51.07   Test_loss.: 0.0761   Test_acc: 31.58\n",
      "Updating Model:  48.421052631578945\n",
      "Epoch: 10    Train_loss.: 0.0767   Train_acc: 57.50   Test_loss.: 0.0725   Test_acc: 48.42\n",
      "Not changed:  48.421052631578945\n",
      "Epoch: 11    Train_loss.: 0.0760   Train_acc: 56.25   Test_loss.: 0.0742   Test_acc: 38.95\n",
      "Updating Model:  53.68421052631579\n",
      "Epoch: 12    Train_loss.: 0.0672   Train_acc: 65.00   Test_loss.: 0.0718   Test_acc: 53.68\n",
      "Not changed:  53.68421052631579\n",
      "Epoch: 13    Train_loss.: 0.0730   Train_acc: 64.64   Test_loss.: 0.0800   Test_acc: 47.37\n",
      "Not changed:  53.68421052631579\n",
      "Epoch: 14    Train_loss.: 0.0703   Train_acc: 67.86   Test_loss.: 0.0784   Test_acc: 47.37\n",
      "Not changed:  53.68421052631579\n",
      "Epoch: 15    Train_loss.: 0.0631   Train_acc: 68.04   Test_loss.: 0.0738   Test_acc: 43.16\n",
      "Not changed:  53.68421052631579\n",
      "Epoch: 16    Train_loss.: 0.0583   Train_acc: 72.32   Test_loss.: 0.0774   Test_acc: 41.05\n",
      "Not changed:  53.68421052631579\n",
      "Epoch: 17    Train_loss.: 0.0631   Train_acc: 61.25   Test_loss.: 0.0734   Test_acc: 46.32\n",
      "Not changed:  53.68421052631579\n",
      "Epoch: 18    Train_loss.: 0.0570   Train_acc: 55.18   Test_loss.: 0.1115   Test_acc: 45.26\n",
      "Not changed:  53.68421052631579\n",
      "Epoch: 19    Train_loss.: 0.0533   Train_acc: 71.96   Test_loss.: 0.0765   Test_acc: 48.42\n",
      "Updating Model:  63.1578947368421\n",
      "Epoch: 20    Train_loss.: 0.0558   Train_acc: 74.64   Test_loss.: 0.0587   Test_acc: 63.16\n",
      "Not changed:  63.1578947368421\n",
      "Epoch: 21    Train_loss.: 0.0517   Train_acc: 65.36   Test_loss.: 0.0548   Test_acc: 60.00\n",
      "Updating Model:  75.78947368421052\n",
      "Epoch: 22    Train_loss.: 0.0500   Train_acc: 81.43   Test_loss.: 0.0504   Test_acc: 75.79\n",
      "Not changed:  75.78947368421052\n",
      "Epoch: 23    Train_loss.: 0.0421   Train_acc: 59.82   Test_loss.: 0.0736   Test_acc: 52.63\n",
      "Not changed:  75.78947368421052\n",
      "Epoch: 24    Train_loss.: 0.0446   Train_acc: 81.07   Test_loss.: 0.0477   Test_acc: 65.26\n",
      "Not changed:  75.78947368421052\n",
      "Epoch: 25    Train_loss.: 0.0422   Train_acc: 78.57   Test_loss.: 0.0527   Test_acc: 73.68\n",
      "Not changed:  75.78947368421052\n",
      "Epoch: 26    Train_loss.: 0.0429   Train_acc: 77.50   Test_loss.: 0.0656   Test_acc: 56.84\n",
      "Not changed:  75.78947368421052\n",
      "Epoch: 27    Train_loss.: 0.0365   Train_acc: 86.96   Test_loss.: 0.0470   Test_acc: 69.47\n",
      "Not changed:  75.78947368421052\n",
      "Epoch: 28    Train_loss.: 0.0378   Train_acc: 83.39   Test_loss.: 0.0547   Test_acc: 67.37\n",
      "Not changed:  75.78947368421052\n",
      "Epoch: 29    Train_loss.: 0.0406   Train_acc: 78.93   Test_loss.: 0.0537   Test_acc: 67.37\n",
      "Not changed:  75.78947368421052\n",
      "Epoch: 30    Train_loss.: 0.0353   Train_acc: 79.46   Test_loss.: 0.0577   Test_acc: 63.16\n",
      "Updating Model:  77.89473684210526\n",
      "Epoch: 31    Train_loss.: 0.0399   Train_acc: 84.64   Test_loss.: 0.0412   Test_acc: 77.89\n",
      "Not changed:  77.89473684210526\n",
      "Epoch: 32    Train_loss.: 0.0369   Train_acc: 78.04   Test_loss.: 0.0609   Test_acc: 63.16\n",
      "Not changed:  77.89473684210526\n",
      "Epoch: 33    Train_loss.: 0.0296   Train_acc: 79.64   Test_loss.: 0.0472   Test_acc: 70.53\n",
      "Not changed:  77.89473684210526\n",
      "Epoch: 34    Train_loss.: 0.0305   Train_acc: 89.11   Test_loss.: 0.0589   Test_acc: 71.58\n",
      "Not changed:  77.89473684210526\n",
      "Epoch: 35    Train_loss.: 0.0318   Train_acc: 80.71   Test_loss.: 0.0367   Test_acc: 76.84\n",
      "Not changed:  77.89473684210526\n",
      "Epoch: 36    Train_loss.: 0.0289   Train_acc: 88.75   Test_loss.: 0.0396   Test_acc: 77.89\n",
      "Not changed:  77.89473684210526\n",
      "Epoch: 37    Train_loss.: 0.0312   Train_acc: 72.32   Test_loss.: 0.0654   Test_acc: 68.42\n",
      "Updating Model:  78.94736842105263\n",
      "Epoch: 38    Train_loss.: 0.0294   Train_acc: 87.32   Test_loss.: 0.0391   Test_acc: 78.95\n",
      "Not changed:  78.94736842105263\n",
      "Epoch: 39    Train_loss.: 0.0313   Train_acc: 88.93   Test_loss.: 0.0471   Test_acc: 71.58\n",
      "Not changed:  78.94736842105263\n",
      "Epoch: 40    Train_loss.: 0.0280   Train_acc: 72.86   Test_loss.: 0.0714   Test_acc: 65.26\n",
      "Not changed:  78.94736842105263\n",
      "Epoch: 41    Train_loss.: 0.0318   Train_acc: 86.79   Test_loss.: 0.0454   Test_acc: 73.68\n",
      "Not changed:  78.94736842105263\n",
      "Epoch: 42    Train_loss.: 0.0323   Train_acc: 90.54   Test_loss.: 0.0443   Test_acc: 74.74\n",
      "Not changed:  78.94736842105263\n",
      "Epoch: 43    Train_loss.: 0.0271   Train_acc: 90.71   Test_loss.: 0.0432   Test_acc: 71.58\n",
      "Updating Model:  83.15789473684211\n",
      "Epoch: 44    Train_loss.: 0.0221   Train_acc: 92.68   Test_loss.: 0.0352   Test_acc: 83.16\n",
      "Not changed:  83.15789473684211\n",
      "Epoch: 45    Train_loss.: 0.0226   Train_acc: 88.93   Test_loss.: 0.0385   Test_acc: 80.00\n",
      "Not changed:  83.15789473684211\n",
      "Epoch: 46    Train_loss.: 0.0223   Train_acc: 90.18   Test_loss.: 0.0576   Test_acc: 78.95\n",
      "Not changed:  83.15789473684211\n",
      "Epoch: 47    Train_loss.: 0.0236   Train_acc: 88.39   Test_loss.: 0.0419   Test_acc: 77.89\n",
      "Not changed:  83.15789473684211\n",
      "Epoch: 48    Train_loss.: 0.0222   Train_acc: 88.39   Test_loss.: 0.0378   Test_acc: 78.95\n",
      "Not changed:  83.15789473684211\n",
      "Epoch: 49    Train_loss.: 0.0296   Train_acc: 81.61   Test_loss.: 0.0579   Test_acc: 74.74\n",
      "Not changed:  83.15789473684211\n",
      "Epoch: 50    Train_loss.: 0.0300   Train_acc: 89.29   Test_loss.: 0.0362   Test_acc: 74.74\n",
      "Not changed:  83.15789473684211\n",
      "Epoch: 51    Train_loss.: 0.0262   Train_acc: 90.71   Test_loss.: 0.0447   Test_acc: 69.47\n",
      "Not changed:  83.15789473684211\n",
      "Epoch: 52    Train_loss.: 0.0230   Train_acc: 92.32   Test_loss.: 0.0307   Test_acc: 81.05\n",
      "Not changed:  83.15789473684211\n",
      "Epoch: 53    Train_loss.: 0.0265   Train_acc: 87.86   Test_loss.: 0.0361   Test_acc: 77.89\n",
      "Not changed:  83.15789473684211\n",
      "Epoch: 54    Train_loss.: 0.0293   Train_acc: 93.21   Test_loss.: 0.0434   Test_acc: 76.84\n",
      "Not changed:  83.15789473684211\n",
      "Epoch: 55    Train_loss.: 0.0226   Train_acc: 84.64   Test_loss.: 0.0633   Test_acc: 78.95\n",
      "Not changed:  83.15789473684211\n",
      "Epoch: 56    Train_loss.: 0.0250   Train_acc: 85.36   Test_loss.: 0.0353   Test_acc: 80.00\n",
      "Not changed:  83.15789473684211\n",
      "Epoch: 57    Train_loss.: 0.0229   Train_acc: 92.32   Test_loss.: 0.0474   Test_acc: 77.89\n",
      "Not changed:  83.15789473684211\n",
      "Epoch: 58    Train_loss.: 0.0200   Train_acc: 92.32   Test_loss.: 0.0394   Test_acc: 74.74\n",
      "Not changed:  83.15789473684211\n",
      "Epoch: 59    Train_loss.: 0.0195   Train_acc: 90.71   Test_loss.: 0.0369   Test_acc: 80.00\n",
      "Not changed:  83.15789473684211\n",
      "Epoch: 60    Train_loss.: 0.0221   Train_acc: 93.04   Test_loss.: 0.0442   Test_acc: 77.89\n",
      "Not changed:  83.15789473684211\n",
      "Epoch: 61    Train_loss.: 0.0261   Train_acc: 93.57   Test_loss.: 0.0481   Test_acc: 72.63\n",
      "Not changed:  83.15789473684211\n",
      "Epoch: 62    Train_loss.: 0.0203   Train_acc: 91.07   Test_loss.: 0.0517   Test_acc: 73.68\n",
      "Not changed:  83.15789473684211\n",
      "Epoch: 63    Train_loss.: 0.0224   Train_acc: 91.61   Test_loss.: 0.0415   Test_acc: 75.79\n",
      "Not changed:  83.15789473684211\n",
      "Epoch: 64    Train_loss.: 0.0178   Train_acc: 92.32   Test_loss.: 0.0597   Test_acc: 75.79\n",
      "Not changed:  83.15789473684211\n",
      "Epoch: 65    Train_loss.: 0.0165   Train_acc: 95.54   Test_loss.: 0.0385   Test_acc: 76.84\n",
      "Not changed:  83.15789473684211\n",
      "Epoch: 66    Train_loss.: 0.0178   Train_acc: 78.21   Test_loss.: 0.0648   Test_acc: 70.53\n",
      "Not changed:  83.15789473684211\n",
      "Epoch: 67    Train_loss.: 0.0212   Train_acc: 88.04   Test_loss.: 0.0516   Test_acc: 74.74\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Not changed:  83.15789473684211\n",
      "Epoch: 68    Train_loss.: 0.0194   Train_acc: 92.50   Test_loss.: 0.0330   Test_acc: 78.95\n",
      "Not changed:  83.15789473684211\n",
      "Epoch: 69    Train_loss.: 0.0167   Train_acc: 95.00   Test_loss.: 0.0396   Test_acc: 81.05\n",
      "Not changed:  83.15789473684211\n",
      "Epoch: 70    Train_loss.: 0.0173   Train_acc: 93.39   Test_loss.: 0.0454   Test_acc: 82.11\n",
      "Not changed:  83.15789473684211\n",
      "Epoch: 71    Train_loss.: 0.0244   Train_acc: 95.18   Test_loss.: 0.0471   Test_acc: 78.95\n",
      "Not changed:  83.15789473684211\n",
      "Epoch: 72    Train_loss.: 0.0186   Train_acc: 95.00   Test_loss.: 0.0476   Test_acc: 77.89\n",
      "Not changed:  83.15789473684211\n",
      "Epoch: 73    Train_loss.: 0.0198   Train_acc: 94.29   Test_loss.: 0.0329   Test_acc: 82.11\n",
      "Not changed:  83.15789473684211\n",
      "Epoch: 74    Train_loss.: 0.0191   Train_acc: 92.32   Test_loss.: 0.0657   Test_acc: 75.79\n",
      "Updating Model:  86.3157894736842\n",
      "Epoch: 75    Train_loss.: 0.0188   Train_acc: 94.11   Test_loss.: 0.0391   Test_acc: 86.32\n",
      "Not changed:  86.3157894736842\n",
      "Epoch: 76    Train_loss.: 0.0148   Train_acc: 94.11   Test_loss.: 0.0471   Test_acc: 78.95\n",
      "Not changed:  86.3157894736842\n",
      "Epoch: 77    Train_loss.: 0.0199   Train_acc: 93.57   Test_loss.: 0.0415   Test_acc: 76.84\n",
      "Not changed:  86.3157894736842\n",
      "Epoch: 78    Train_loss.: 0.0162   Train_acc: 95.36   Test_loss.: 0.0375   Test_acc: 81.05\n",
      "Not changed:  86.3157894736842\n",
      "Epoch: 79    Train_loss.: 0.0151   Train_acc: 93.39   Test_loss.: 0.0508   Test_acc: 80.00\n",
      "Not changed:  86.3157894736842\n",
      "Epoch: 80    Train_loss.: 0.0167   Train_acc: 94.82   Test_loss.: 0.0490   Test_acc: 81.05\n",
      "Not changed:  86.3157894736842\n",
      "Epoch: 81    Train_loss.: 0.0170   Train_acc: 91.43   Test_loss.: 0.0684   Test_acc: 70.53\n",
      "Not changed:  86.3157894736842\n",
      "Epoch: 82    Train_loss.: 0.0178   Train_acc: 96.96   Test_loss.: 0.0392   Test_acc: 85.26\n",
      "Not changed:  86.3157894736842\n",
      "Epoch: 83    Train_loss.: 0.0149   Train_acc: 95.00   Test_loss.: 0.0515   Test_acc: 77.89\n",
      "Updating Model:  87.36842105263158\n",
      "Epoch: 84    Train_loss.: 0.0131   Train_acc: 96.79   Test_loss.: 0.0315   Test_acc: 87.37\n",
      "Not changed:  87.36842105263158\n",
      "Epoch: 85    Train_loss.: 0.0161   Train_acc: 94.64   Test_loss.: 0.0455   Test_acc: 81.05\n",
      "Not changed:  87.36842105263158\n",
      "Epoch: 86    Train_loss.: 0.0135   Train_acc: 95.89   Test_loss.: 0.0631   Test_acc: 76.84\n",
      "Not changed:  87.36842105263158\n",
      "Epoch: 87    Train_loss.: 0.0152   Train_acc: 92.86   Test_loss.: 0.0403   Test_acc: 83.16\n",
      "Not changed:  87.36842105263158\n",
      "Epoch: 88    Train_loss.: 0.0157   Train_acc: 91.07   Test_loss.: 0.0559   Test_acc: 73.68\n",
      "Not changed:  87.36842105263158\n",
      "Epoch: 89    Train_loss.: 0.0172   Train_acc: 96.43   Test_loss.: 0.0429   Test_acc: 85.26\n",
      "Not changed:  87.36842105263158\n",
      "Epoch: 90    Train_loss.: 0.0134   Train_acc: 95.89   Test_loss.: 0.0577   Test_acc: 75.79\n",
      "Updating Model:  88.42105263157895\n",
      "Epoch: 91    Train_loss.: 0.0169   Train_acc: 96.43   Test_loss.: 0.0380   Test_acc: 88.42\n",
      "Not changed:  88.42105263157895\n",
      "Epoch: 92    Train_loss.: 0.0118   Train_acc: 86.61   Test_loss.: 0.0560   Test_acc: 78.95\n",
      "Not changed:  88.42105263157895\n",
      "Epoch: 93    Train_loss.: 0.0176   Train_acc: 95.54   Test_loss.: 0.0413   Test_acc: 83.16\n",
      "Not changed:  88.42105263157895\n",
      "Epoch: 94    Train_loss.: 0.0156   Train_acc: 96.79   Test_loss.: 0.0454   Test_acc: 84.21\n",
      "Not changed:  88.42105263157895\n",
      "Epoch: 95    Train_loss.: 0.0190   Train_acc: 93.93   Test_loss.: 0.0477   Test_acc: 81.05\n",
      "Not changed:  88.42105263157895\n",
      "Epoch: 96    Train_loss.: 0.0208   Train_acc: 96.07   Test_loss.: 0.0448   Test_acc: 83.16\n",
      "Not changed:  88.42105263157895\n",
      "Epoch: 97    Train_loss.: 0.0132   Train_acc: 96.43   Test_loss.: 0.0687   Test_acc: 78.95\n",
      "Not changed:  88.42105263157895\n",
      "Epoch: 98    Train_loss.: 0.0110   Train_acc: 96.61   Test_loss.: 0.0373   Test_acc: 86.32\n",
      "Not changed:  88.42105263157895\n",
      "Epoch: 99    Train_loss.: 0.0100   Train_acc: 97.68   Test_loss.: 0.0365   Test_acc: 88.42\n",
      "Not changed:  88.42105263157895\n",
      "Epoch: 100    Train_loss.: 0.0097   Train_acc: 96.61   Test_loss.: 0.0544   Test_acc: 84.21\n",
      "Not changed:  88.42105263157895\n",
      "Epoch: 101    Train_loss.: 0.0120   Train_acc: 98.39   Test_loss.: 0.0415   Test_acc: 85.26\n",
      "Not changed:  88.42105263157895\n",
      "Epoch: 102    Train_loss.: 0.0119   Train_acc: 96.61   Test_loss.: 0.0483   Test_acc: 83.16\n",
      "Not changed:  88.42105263157895\n",
      "Epoch: 103    Train_loss.: 0.0142   Train_acc: 97.50   Test_loss.: 0.0510   Test_acc: 77.89\n",
      "Not changed:  88.42105263157895\n",
      "Epoch: 104    Train_loss.: 0.0131   Train_acc: 92.86   Test_loss.: 0.0725   Test_acc: 68.42\n",
      "Not changed:  88.42105263157895\n",
      "Epoch: 105    Train_loss.: 0.0124   Train_acc: 91.79   Test_loss.: 0.0626   Test_acc: 74.74\n",
      "Not changed:  88.42105263157895\n",
      "Epoch: 106    Train_loss.: 0.0143   Train_acc: 96.61   Test_loss.: 0.0540   Test_acc: 81.05\n",
      "Not changed:  88.42105263157895\n",
      "Epoch: 107    Train_loss.: 0.0082   Train_acc: 97.86   Test_loss.: 0.0523   Test_acc: 80.00\n",
      "Not changed:  88.42105263157895\n",
      "Epoch: 108    Train_loss.: 0.0110   Train_acc: 97.32   Test_loss.: 0.0423   Test_acc: 85.26\n",
      "Not changed:  88.42105263157895\n",
      "Epoch: 109    Train_loss.: 0.0144   Train_acc: 92.50   Test_loss.: 0.0671   Test_acc: 73.68\n",
      "Not changed:  88.42105263157895\n",
      "Epoch: 110    Train_loss.: 0.0191   Train_acc: 94.46   Test_loss.: 0.0497   Test_acc: 80.00\n",
      "Not changed:  88.42105263157895\n",
      "Epoch: 111    Train_loss.: 0.0153   Train_acc: 95.00   Test_loss.: 0.0607   Test_acc: 76.84\n",
      "Not changed:  88.42105263157895\n",
      "Epoch: 112    Train_loss.: 0.0111   Train_acc: 98.04   Test_loss.: 0.0562   Test_acc: 83.16\n",
      "Not changed:  88.42105263157895\n",
      "Epoch: 113    Train_loss.: 0.0111   Train_acc: 95.18   Test_loss.: 0.0566   Test_acc: 83.16\n",
      "Not changed:  88.42105263157895\n",
      "Epoch: 114    Train_loss.: 0.0161   Train_acc: 95.00   Test_loss.: 0.0479   Test_acc: 81.05\n",
      "Not changed:  88.42105263157895\n",
      "Epoch: 115    Train_loss.: 0.0228   Train_acc: 76.25   Test_loss.: 0.1367   Test_acc: 62.11\n",
      "Not changed:  88.42105263157895\n",
      "Epoch: 116    Train_loss.: 0.0152   Train_acc: 96.07   Test_loss.: 0.0707   Test_acc: 77.89\n",
      "Not changed:  88.42105263157895\n",
      "Epoch: 117    Train_loss.: 0.0204   Train_acc: 92.86   Test_loss.: 0.0479   Test_acc: 72.63\n",
      "Not changed:  88.42105263157895\n",
      "Epoch: 118    Train_loss.: 0.0141   Train_acc: 90.00   Test_loss.: 0.0422   Test_acc: 83.16\n",
      "Not changed:  88.42105263157895\n",
      "Epoch: 119    Train_loss.: 0.0103   Train_acc: 97.86   Test_loss.: 0.0386   Test_acc: 87.37\n",
      "Not changed:  88.42105263157895\n",
      "Epoch: 120    Train_loss.: 0.0097   Train_acc: 95.71   Test_loss.: 0.0358   Test_acc: 82.11\n",
      "Updating Model:  89.47368421052632\n",
      "Epoch: 121    Train_loss.: 0.0108   Train_acc: 96.96   Test_loss.: 0.0386   Test_acc: 89.47\n",
      "Not changed:  89.47368421052632\n",
      "Epoch: 122    Train_loss.: 0.0120   Train_acc: 95.89   Test_loss.: 0.0573   Test_acc: 83.16\n",
      "Not changed:  89.47368421052632\n",
      "Epoch: 123    Train_loss.: 0.0136   Train_acc: 92.14   Test_loss.: 0.0747   Test_acc: 78.95\n",
      "Not changed:  89.47368421052632\n",
      "Epoch: 124    Train_loss.: 0.0126   Train_acc: 96.07   Test_loss.: 0.0536   Test_acc: 82.11\n",
      "Not changed:  89.47368421052632\n",
      "Epoch: 125    Train_loss.: 0.0080   Train_acc: 98.21   Test_loss.: 0.0787   Test_acc: 81.05\n",
      "Not changed:  89.47368421052632\n",
      "Epoch: 126    Train_loss.: 0.0082   Train_acc: 97.68   Test_loss.: 0.0785   Test_acc: 81.05\n",
      "Not changed:  89.47368421052632\n",
      "Epoch: 127    Train_loss.: 0.0081   Train_acc: 96.79   Test_loss.: 0.0619   Test_acc: 82.11\n",
      "Not changed:  89.47368421052632\n",
      "Epoch: 128    Train_loss.: 0.0205   Train_acc: 91.43   Test_loss.: 0.0914   Test_acc: 63.16\n",
      "Not changed:  89.47368421052632\n",
      "Epoch: 129    Train_loss.: 0.0138   Train_acc: 92.50   Test_loss.: 0.0962   Test_acc: 80.00\n",
      "Not changed:  89.47368421052632\n",
      "Epoch: 130    Train_loss.: 0.0149   Train_acc: 81.07   Test_loss.: 0.1015   Test_acc: 72.63\n",
      "Not changed:  89.47368421052632\n",
      "Epoch: 131    Train_loss.: 0.0133   Train_acc: 96.43   Test_loss.: 0.0656   Test_acc: 80.00\n",
      "Not changed:  89.47368421052632\n",
      "Epoch: 132    Train_loss.: 0.0123   Train_acc: 92.32   Test_loss.: 0.0546   Test_acc: 86.32\n",
      "Not changed:  89.47368421052632\n",
      "Epoch: 133    Train_loss.: 0.0121   Train_acc: 98.21   Test_loss.: 0.0556   Test_acc: 83.16\n",
      "Not changed:  89.47368421052632\n",
      "Epoch: 134    Train_loss.: 0.0092   Train_acc: 97.32   Test_loss.: 0.0773   Test_acc: 83.16\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Not changed:  89.47368421052632\n",
      "Epoch: 135    Train_loss.: 0.0109   Train_acc: 98.04   Test_loss.: 0.0611   Test_acc: 86.32\n",
      "Not changed:  89.47368421052632\n",
      "Epoch: 136    Train_loss.: 0.0095   Train_acc: 95.18   Test_loss.: 0.0696   Test_acc: 78.95\n",
      "Not changed:  89.47368421052632\n",
      "Epoch: 137    Train_loss.: 0.0131   Train_acc: 85.54   Test_loss.: 0.0833   Test_acc: 73.68\n",
      "Not changed:  89.47368421052632\n",
      "Epoch: 138    Train_loss.: 0.0089   Train_acc: 97.50   Test_loss.: 0.0531   Test_acc: 86.32\n",
      "Not changed:  89.47368421052632\n",
      "Epoch: 139    Train_loss.: 0.0133   Train_acc: 98.39   Test_loss.: 0.0632   Test_acc: 82.11\n",
      "Not changed:  89.47368421052632\n",
      "Epoch: 140    Train_loss.: 0.0107   Train_acc: 98.57   Test_loss.: 0.0578   Test_acc: 84.21\n",
      "Not changed:  89.47368421052632\n",
      "Epoch: 141    Train_loss.: 0.0068   Train_acc: 98.39   Test_loss.: 0.0819   Test_acc: 84.21\n",
      "Not changed:  89.47368421052632\n",
      "Epoch: 142    Train_loss.: 0.0091   Train_acc: 98.21   Test_loss.: 0.0782   Test_acc: 85.26\n",
      "Not changed:  89.47368421052632\n",
      "Epoch: 143    Train_loss.: 0.0073   Train_acc: 97.68   Test_loss.: 0.0716   Test_acc: 86.32\n",
      "Updating Model:  90.52631578947368\n",
      "Epoch: 144    Train_loss.: 0.0065   Train_acc: 99.29   Test_loss.: 0.0586   Test_acc: 90.53\n",
      "Not changed:  90.52631578947368\n",
      "Epoch: 145    Train_loss.: 0.0117   Train_acc: 95.54   Test_loss.: 0.0503   Test_acc: 87.37\n",
      "Not changed:  90.52631578947368\n",
      "Epoch: 146    Train_loss.: 0.0099   Train_acc: 99.11   Test_loss.: 0.0387   Test_acc: 87.37\n",
      "Not changed:  90.52631578947368\n",
      "Epoch: 147    Train_loss.: 0.0106   Train_acc: 98.75   Test_loss.: 0.0284   Test_acc: 90.53\n",
      "Not changed:  90.52631578947368\n",
      "Epoch: 148    Train_loss.: 0.0101   Train_acc: 99.11   Test_loss.: 0.0606   Test_acc: 88.42\n",
      "Not changed:  90.52631578947368\n",
      "Epoch: 149    Train_loss.: 0.0097   Train_acc: 98.21   Test_loss.: 0.0963   Test_acc: 82.11\n",
      "Not changed:  90.52631578947368\n",
      "Epoch: 150    Train_loss.: 0.0076   Train_acc: 97.32   Test_loss.: 0.0797   Test_acc: 77.89\n",
      "Not changed:  90.52631578947368\n",
      "Epoch: 151    Train_loss.: 0.0102   Train_acc: 98.93   Test_loss.: 0.0702   Test_acc: 81.05\n",
      "Not changed:  90.52631578947368\n",
      "Epoch: 152    Train_loss.: 0.0065   Train_acc: 98.39   Test_loss.: 0.0795   Test_acc: 80.00\n",
      "Not changed:  90.52631578947368\n",
      "Epoch: 153    Train_loss.: 0.0116   Train_acc: 94.11   Test_loss.: 0.0893   Test_acc: 72.63\n",
      "Not changed:  90.52631578947368\n",
      "Epoch: 154    Train_loss.: 0.0092   Train_acc: 98.57   Test_loss.: 0.0486   Test_acc: 87.37\n",
      "Not changed:  90.52631578947368\n",
      "Epoch: 155    Train_loss.: 0.0080   Train_acc: 98.75   Test_loss.: 0.0761   Test_acc: 81.05\n",
      "Not changed:  90.52631578947368\n",
      "Epoch: 156    Train_loss.: 0.0073   Train_acc: 98.21   Test_loss.: 0.0804   Test_acc: 82.11\n",
      "Not changed:  90.52631578947368\n",
      "Epoch: 157    Train_loss.: 0.0079   Train_acc: 98.21   Test_loss.: 0.0664   Test_acc: 82.11\n",
      "Not changed:  90.52631578947368\n",
      "Epoch: 158    Train_loss.: 0.0094   Train_acc: 99.29   Test_loss.: 0.0807   Test_acc: 75.79\n",
      "Not changed:  90.52631578947368\n",
      "Epoch: 159    Train_loss.: 0.0071   Train_acc: 98.93   Test_loss.: 0.0855   Test_acc: 82.11\n",
      "Not changed:  90.52631578947368\n",
      "Epoch: 160    Train_loss.: 0.0073   Train_acc: 97.86   Test_loss.: 0.0532   Test_acc: 87.37\n",
      "Not changed:  90.52631578947368\n",
      "Epoch: 161    Train_loss.: 0.0054   Train_acc: 99.46   Test_loss.: 0.0866   Test_acc: 84.21\n",
      "Not changed:  90.52631578947368\n",
      "Epoch: 162    Train_loss.: 0.0116   Train_acc: 96.43   Test_loss.: 0.0941   Test_acc: 86.32\n",
      "Not changed:  90.52631578947368\n",
      "Epoch: 163    Train_loss.: 0.0078   Train_acc: 93.75   Test_loss.: 0.0768   Test_acc: 82.11\n",
      "Not changed:  90.52631578947368\n",
      "Epoch: 164    Train_loss.: 0.0084   Train_acc: 98.93   Test_loss.: 0.0825   Test_acc: 81.05\n",
      "Not changed:  90.52631578947368\n",
      "Epoch: 165    Train_loss.: 0.0077   Train_acc: 98.75   Test_loss.: 0.0734   Test_acc: 84.21\n",
      "Not changed:  90.52631578947368\n",
      "Epoch: 166    Train_loss.: 0.0088   Train_acc: 96.43   Test_loss.: 0.0607   Test_acc: 87.37\n",
      "Not changed:  90.52631578947368\n",
      "Epoch: 167    Train_loss.: 0.0152   Train_acc: 93.04   Test_loss.: 0.0748   Test_acc: 76.84\n",
      "Not changed:  90.52631578947368\n",
      "Epoch: 168    Train_loss.: 0.0084   Train_acc: 97.14   Test_loss.: 0.0658   Test_acc: 80.00\n",
      "Not changed:  90.52631578947368\n",
      "Epoch: 169    Train_loss.: 0.0081   Train_acc: 96.25   Test_loss.: 0.0512   Test_acc: 86.32\n",
      "Not changed:  90.52631578947368\n",
      "Epoch: 170    Train_loss.: 0.0088   Train_acc: 98.75   Test_loss.: 0.0741   Test_acc: 83.16\n"
     ]
    }
   ],
   "source": [
    "no_of_epochs = 170\n",
    "best_accuracy = 0\n",
    "for i in range(1, no_of_epochs + 1):\n",
    "    network.train()\n",
    "    train_loss, train_acc = train()\n",
    "    network.eval()\n",
    "    test_loss, test_acc = test()\n",
    "    if test_acc > best_accuracy:\n",
    "        torch.save(network.state_dict(), 'best_model_parameters_1.ckpt')\n",
    "        best_accuracy = test_acc\n",
    "        print(\"Updating Model: \",best_accuracy)\n",
    "    else:\n",
    "        print(\"Not changed: \",best_accuracy)\n",
    "    print(\"Epoch: {}    Train_loss.: {:.4f}   Train_acc: {:.2f}   Test_loss.: {:.4f}   Test_acc: {:.2f}\".format(i, train_loss,train_acc,test_loss,test_acc))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#torch.save(network.state_dict(), 'network.ckpt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<All keys matched successfully>"
      ]
     },
     "execution_count": 98,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "network.load_state_dict(torch.load('best_model_parameters_1.ckpt'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [],
   "source": [
    "test = datasets.ImageFolder(\"C://Users/Atharva/Dataset/test\", transform = test_transformations)\n",
    "verify_dataloader = torch.utils.data.DataLoader(test, batch_size=95, shuffle=False, num_workers=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy 90.52631578947368\n"
     ]
    }
   ],
   "source": [
    "network.eval()# it-disables-dropout\n",
    "with torch.no_grad():\n",
    "    correct=0\n",
    "    total=0\n",
    "    for data in test_dataloader:\n",
    "            \n",
    "        images, labels = data\n",
    "        images = images.to(device)\n",
    "        labels = labels.to(device)\n",
    "            \n",
    "        outputs = network(images)\n",
    "            \n",
    "        _, predicted = torch.max(outputs.data, 1)\n",
    "        total += labels.size(0)\n",
    "        correct += (predicted == labels).sum().item()\n",
    "    print(\"Accuracy\",correct*100/total)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [],
   "source": [
    "images, labels = next(iter(verify_dataloader))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [],
   "source": [
    "output = []\n",
    "with torch.no_grad():\n",
    "    correct=0\n",
    "    total=0\n",
    "    for data in verify_dataloader:\n",
    "            \n",
    "        images, labels = data\n",
    "        images = images.to(device)\n",
    "        labels = labels.to(device)\n",
    "            \n",
    "        outputs = network(images)\n",
    "            \n",
    "        _, predicted = torch.max(outputs.data, 1)\n",
    "    output = predicted"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([0, 3, 3, 2, 3, 6, 1, 3, 4, 5, 3, 1, 0, 3, 3, 6, 1, 0, 3, 3, 3, 3, 4, 3,\n",
       "        4, 0, 3, 3, 5, 2, 1, 3, 3, 5, 0, 0, 3, 3, 0, 3, 3, 3, 1, 4, 3, 1, 5, 0,\n",
       "        2, 5, 5, 4, 2, 3, 0, 2, 6, 3, 3, 6, 3, 4, 2, 1, 3, 3, 3, 5, 1, 2, 3, 4,\n",
       "        3, 6, 2, 3, 1, 5, 2, 3, 0, 1, 1, 4, 5, 6, 3, 4, 2, 3, 4, 3, 5, 0, 3],\n",
       "       device='cuda:0')"
      ]
     },
     "execution_count": 103,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [],
   "source": [
    "classes = []\n",
    "for i in output:\n",
    "    classes.append(req_classes[i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [],
   "source": [
    "#classes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [],
   "source": [
    "image_id = list(np.array(range(1001,1096)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.DataFrame({\"ImageID\":image_id,\"Label\":classes})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.to_csv(\"180010014_1.csv\",index=False,header=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
